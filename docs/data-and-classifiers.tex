\section{Przetwarzanie danych}
	\subsection{Konwersja plików XML do formatu CSV}
	Ze względu na nieefektywność przetwarzania plików XML oraz na dużą ilość niepotrzebnych danych znajdujących się w korpusach, postanowiono przetworzyć je do formy plików CSV.
Proces zamiany plików XML odbywa się dla obydwu korpusów -- PWr oraz podkorpusu milionowego.
	Niestety, ze względu na rozbieżność struktur nie mogą one być przetworzone w ten sam sposób.
	
\begin{sloppypar}
Do pliku CSV zapisywane są dwie informacje -- słowo oraz część mowy.
Wyrażenia XPath służące do wydobycia tych danych z korpusu PWr wyglądają następująco:
\texttt{//tok/orth} -- dla wyrazu, oraz \texttt{//tok/lex[disamb='1']} dla części mowy. Dla podkorpusu milionowego zapytania XPath prezentują się w sposób następujący: \texttt{//f[name='orth']/string} dla wyrazu, oraz \texttt{//f[name='disamb']/f[name='interpretation']/string} dla części mowy.
\end{sloppypar}

	\subsection{Mapowanie klas NKJP}
Oba korpusy wykorzystują zestaw znaczników morfosyntaktycznych NKJP, który wyróżnia 36 rodzajów klas.
Na potrzeby projektu liczba ta została ograniczona do 10 podstawowych części mowy. Poniżej zostało przedstawione mapowanie z klas NKJP na uproszczony model.
\begin{table}[H]
	\centering
	\caption{Mapowanie klas NKJP.}
	\begin{tabular}{p{3cm}p{.5cm}p{11cm}}
		\toprule
		\texttt{rzeczownik} & $\leftarrow$ & rzeczownik, rzeczownik deprecjatywny. \\
		\texttt{liczebnik} & $\leftarrow$ & liczebnik główny, liczebnik zbiorowy. \\
		\texttt{przymiotnik} & $\leftarrow$ & przymiotnik, przymiotnik przyprzym., przymiotnik poprzyimkowy, przymiotnik predykatywny. \\
		\texttt{przysłówek} & $\leftarrow$ & przysłówek. \\
		\texttt{zaimek} & $\leftarrow$ & zaimek nietrzecioosobowy, zaimek trzecioosobowy, zaimek siebie. \\
		\texttt{czasownik} & $\leftarrow$ & forma nieprzeszła, forma przyszła być, aglutynant być, pseudoimiesłów, rozkaźnik, bezosobnik, bezokolicznik, im. przys. współczesny, im. przys. uprzedni, odsłownik, im. przym. czynny, im. przym. biern, winien, predykatyw. \\
		\texttt{przyimek} & $\leftarrow$ & przyimek, wykrzyknik. \\
		\texttt{spójnik} & $\leftarrow$ & spójnik współrzędny, spójnik podrzędny. \\
		\texttt{partykuła} & $\leftarrow$ & kublik. \\
		\texttt{forma nierozpoznana} & $\leftarrow$ & skrót, burkinostka, interpunkcja, ciało obce, forma nierozpoznana. \\
		\bottomrule
	\end{tabular}
\end{table}

\section{Opis danych}
	System operuje na danych wejściowych, którymi są słowa w języku polskim.
	Istnieje możliwość wprowadzenia zarówno pojedynczego słowa, jak i wielu (np. epitety, całe zdania).
	
	\subsection{Sposób wybierania cech}
	Cechy wybierane są na podstawie budowy słowa oraz kontekstu, w którym zostało użyte.
	W celu wyekstrahowania cech ze słowa, system bada $N$ ostatnich liter wyrazu oraz to, jakie części zdania wystąpiły wcześniej.
	
	W zależności od wyboru użytkownika, system potrafi zebrać dane uczące z korpusu PWr lub z korpusu podmilionowego.
	
	\subsubsection{Zaimplementowana metoda wybierania cech}
	Metoda ekstrakcji cech zaimplementowana w systemie opiera się na wyodrębnianiu końcówek wyrazów.
	
	Możliwe jest wybranie od jednej do czterech ostatnich liter, z których następnie jest tworzona macierz cech -- wybierane są najczęściej występujące końcówki, wraz z etykietą, którą część mowy stanowią.
	
	Liczba najczęściej występujących końcówek zależy od ich długości:
	\begin{itemize}
		\item 15 najczęstszych końcówek jednoliterowych,
		\item 35 najczęstszych końcówek mających od dwóch do czterech liter.
	\end{itemize}
	
	Oprócz końcówek wyrazów, dla zdań występujących w korpusach, podawane są etykiety poprzednich dwóch wyrazów.
	
	\subsubsection{Przykład macierzy cech}
	Przykładowy zbiór uczący:
	\begin{itemize}
		\item jabłkami -- rzeczownik,
		\item niepoważny -- przymiotnik,
		\item kierunku -- rzeczownik,
		\item istnieje -- czasownik,
		\item wolność -- rzeczownik,
	\end{itemize}
	
	\medskip
	Podane wyrazy nie posiadają danych na temat poprzednich etykiet wyrazów. Można wyróżnić tutaj następujące końcówki:
	\begin{itemize}
		\item i -- rzeczownik,
		\item y -- przymiotnik,
		\item u -- rzeczownik,
		\item e -- czasownik,
		\item ć -- rzeczownik,
		\item mi -- rzeczownik,
		\item ny -- przymiotnik,
		\item ku -- rzeczownik,
		\item je -- czasownik,
		\item ść -- rzeczownik,
		\item ami -- rzeczownik,
		\item żny -- przymiotnik,
		\item nku -- rzeczownik,
		\item eje -- czasownik,
		\item ość -- rzeczownik,
		\item kami -- rzeczownik,
		\item ażny -- przymiotnik,
		\item unku -- rzeczownik,
		\item ieje -- czasownik,
		\item ność -- rzeczownik.
	\end{itemize}
	
	\medskip
	Etykiety są zamieniane na format wykorzystywany przez pakiet \texttt{scikit-learn} przy pomocy klasy \texttt{DictVectorizer}:
	\begin{itemize}
		\item rzeczownik $\rightarrow$ 0
		\item przymiotnik $\rightarrow$ 1
		\item czasownik $\rightarrow$ 2
		\item --- (b.d.) $\rightarrow$ 3
	\end{itemize}
	
	\begin{landscape}
	\newcommand{\hl}[1]{\colorbox{black!20!white}{#1}}
	\noindent Dla podanego zbioru uczącego można wyróżnić macierz cech (końcówki liter $\rightarrow$ czy dany wyraz kończy się na daną końcówkę):
	\begin{table}[H]
	\caption{Przykładowa macierz cech.}
	\footnotesize
	%\hskip-1.2cm
	\centering
	\begin{tabular}{l|cccccccccccccccccccc|ccc}
	\toprule
	& i & y & u & e & ć & mi & ny & ku & je & ść & ami & żny & nku & eje & ość & kami & ażny & unku & ieje & ność & etykieta w. n-1 & etykieta w. n-2 & etykieta \\
	\midrule
	jabłkami & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & 3 & 3 & 0 \\
	niepoważny & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 3 & 3 & 1 \\
	kierunku & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 3 & 3 & 0 \\
	istnieje & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 3 & 3 & 2 \\
	wolność & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 0 & 0 & 0 & 0 & \hl{1} & 3 & 3 & 0 \\
	\bottomrule
	\end{tabular}
	\end{table}
	\normalsize
	Legenda:\\
	\begin{tabular}{lcl}
		\colorbox{white}{0} & -- & brak danej cechy w obiekcie \\
		\hl{1} & -- & dana cecha występuje dla obiektu \\
	\end{tabular}
	\end{landscape}
	
	\subsection{Wykorzystane klasyfikatory}
	Projekt wykorzystuje wiele klasyfikatorów. Wszystkie klasyfikatory z pakietu \texttt{scikit-learn} podczas procesu uczenia używają domyślnych parametrów. Więcej informacji można uzyskać w dokumentacji pakietu, dostępnej pod adresem: \url{http://scikit-learn.org/stable/modules/classes.html}.
	
	\begin{table}[H]
		\centering
		\caption{Wykorzystane klasyfikatory.}
		\begin{tabular}{p{5cm}p{11cm}}
			\toprule
			\textbf{Nazwa} & \textbf{Opis} \\
			\midrule
			\texttt{DecisionTreeClassifier} & Klasyfikator oparty na drzewie decyzyjnym. \\
			\texttt{SGDClassifier} & Klasyfikator oparty na liniowym modelu z metodą stochastycznego gradientu prostego. \\
			\texttt{SVC} & Klasyfikator reprezentuje model maszyny wektorów nośnych. \\
			\texttt{LogisticRegression} & Klasyfikator oparty na regresji logistycznej. \\
			\texttt{BernoulliNB} & Klasyfikator wykorzystujący model naiwnego klasyfikatora bayesowskiego z rozkładem Bernoulliego. \\
			\texttt{KNeighborsClassifier} & Klasyfikator implementujący mechanizm $k$-najbliższych sąsiadów. \\
			Sieć neuronowa & Klasyfikator wykorzystujący sieć neuronową opartą na bibliotece \texttt{sknn}. Posiada dwie warstwy: \texttt{Rectifier} (z liczbą 100 neuronów) i \texttt{Softmax}. Współczynnik uczenia wynosi 0,01, a liczba iteracji wynosi 10.
			Sieć neuronowa wykorzystująca kartę graficzną -- klasyfikator, podobnie jak powyższy wykorzystuje sieć neuronową, jednakże do implementacji wykorzystano bibliotekę \texttt{TensorFlow}, ponieważ wspiera wykorzystanie karty graficznej. Podobnie jak w poprzednim klasyfikatorze, sieć ta posiada dwie warstwy -- \texttt{Gated Recurrent Unit} z liczbą 50 neuronów oraz warstwę regresji logistycznej, współczynnik uczenia również wynosi 0.01, liczba iteracji wynosi 1000. Klasyfikator wykorzystuje klasę biblioteki \texttt{TensorFlow} -- \texttt{tf.nn.rnn} -- rekurencyjną sieć neuronową. Ze względu na ograniczoną pamięć kart graficznych, dane uczące dzielone są na części, domyślnie po 10 tysięcy próbek. \\
			\bottomrule
		\end{tabular}
	\end{table}