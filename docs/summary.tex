\section{Podsumowanie}

W ramach projektu powstał kompletny system, w którym można wytrenować klasyfikatory, w tym jeden oparty o kartę graficzną. Dzięki systemowi można zbudować tagger części mowy języka polskiego. Lematyzator nie powstał z powodu wielu trudności, do których można zaliczyć: kodowanie danych, określanie klas, punkty, w których zamieniane byłyby końcówki i specyfika języka polskiego zawierająca dużą liczbę wyjątków w odmianie słów.

Przeprowadzone badania czasów klasyfikacji wykazały, że najefektywniejszymi algorytmami są: \texttt{Logistic Regression}, \texttt{SGD}, \texttt{Decision Trees}, \texttt{Naive Bayes} oraz \texttt{Neural Networks}. Uzyskały one bardzo podobne czasy klasyfikacji (dla liczby 2000 wyrazów wyniosły one niecałą sekundę). Algorytmy \texttt{K Neighbors} oraz \texttt{SVM} odznaczyły się stanowczo dłuższymi czasami klasyfikacji, więc nie powinno się ich stosować dla tekstów mających więcej niż kilka tysięcy wyrazów. Algorytmu uczącego na GPU nie udało się zastosować dla korpusu podmilionowego, zaś dla korpusu PWr osiągnął tak wysokie czasy klasyfikacji, że można go uznać za algorytm całkowicie nieefektywny i nie powinien być stosowany przy tego typu zagadnieniach.

Czasy uczenia algorytmów zawierają się w przedziale od 1 do 7 minut z wyłączeniem sieci neuronowych oraz maszyny wektorów nośnych. Uczenie sieci neuronowych z wykorzystaniem korpusu PWr trwało 20 min, natomiast korpusu National godzinę dłużej. Dla \texttt{SVM} czasy te wynosiły odpowiednio 45 minut oraz 23 godziny 30 minut. Czas uczenia algorytmu opartego na GPU wynosił kwadrans (korpus PWr). Dla większości algorytmów czasy były bardzo krótkie, co daje możliwość wielokrotnych zmian parametrów uczenia oraz przeprowadzania testów na komputerach o niewielkich mocach obliczeniowych.

Uzyskanie wysokich skuteczności klasyfikatorów wymaga dobrania odpowiednich parametrów -- liczb n-literowych końcówek. Badania wykazały, że najwyższą skuteczność klasyfikacji otrzymujemy gdy liczba 2, 3, 4 literowych końcówek znajuje się w przedziale $[35, 45]$, a liczba 1 literowych koncówek w przedziale $[15, 32]$. W przypadku, gdy liczba końcówek jest zbyt duża lub zbyt mała skuteczność klasyfikacji gwałtownie spada. Oprócz tego na skuteczność klasyfikacji źle wpływają duże różnice między liczbami 2, 3, 4 literowych końcówek. Według przeprowadzonych różnica dwoma liczbami końcówek powinna wynosić nie więcej niż 10. Najlepszym klasyfikatorem okazał się \texttt{SVM} z najlepszym wynikiem 61,08\% dla korpusu PWr oraz 60,13\% dla korpusu National. Dokładność klasyfikacji można poprawić przez szerszą analizę wejściowych danych (przeprowadzoną przez specjalistów ds. języka polskiego) lub lepszy dobór parametrów.  

